{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6379565c-b8b6-4438-8f2a-a6081c7d1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdfbb0b-d360-4b2a-a035-db22a6aba23a",
   "metadata": {
    "tags": []
   },
   "source": [
    "APIキーは以下のURLから取得できます。  \n",
    "https://platform.openai.com/account/api-keys  \n",
    "\n",
    "【注意】  \n",
    "<font color=\"Crimson\">APIキーが流出すると他人に利用されて料金を請求されます！</font>  \n",
    "絶対に共有してはいけません。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd897dad-06b1-4cda-87a3-bde4940178a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APIキーの読み込み\n",
    "# キーを格納したテキストファイルを指定して読み込み\n",
    "with open(f'{Path.home()}/.private_info/api_key.txt') as f:\n",
    "    openai.api_key = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba51b90-7ad5-46e6-85c6-048dc024eb6e",
   "metadata": {},
   "source": [
    "# ChatGPT APIのリクエスト送信制限について  \n",
    "  \n",
    "時間当たりのトークン量の制限とリクエスト回数の制限があり、どちらかでも引っかかるとエラーになる。  \n",
    "[リミットについての詳細](https://platform.openai.com/docs/guides/rate-limits/overview)  \n",
    "\n",
    "[トークンカウンター](https://platform.openai.com/tokenizer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb25d320-b363-48cb-90bc-d182b27df822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ChatGPT settings\n",
    "def send_request(message: str, role: str, delay: float = None, **kwargs):\n",
    "    \"\"\"\n",
    "    Delay a completion to avoid a rate limit of requests per min (RPM).\n",
    "    Free trial users: 3 RPM\n",
    "    Pay-as-you-go users: 3500 RPM\n",
    "    \"\"\"\n",
    "    if delay:\n",
    "        time.sleep(delay)\n",
    "    messages = []\n",
    "    # system role\n",
    "    if role:\n",
    "        messages.append(\n",
    "            {'role': 'system', 'content': role},\n",
    "        )\n",
    "    # input message\n",
    "    messages.append(\n",
    "        {'role': 'user', 'content': message},\n",
    "    )\n",
    "    # send request\n",
    "    chat_completion = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=messages,\n",
    "        **kwargs\n",
    "    )\n",
    "    # get reply\n",
    "    reply = chat_completion.choices[0].message.content\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e76af55-a11a-44cc-90fa-4ee7a2fec66a",
   "metadata": {},
   "source": [
    "# CSV処理関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715c0a6e-a410-4e13-82a6-9aba7c3bc086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reply_to_csv(path: str,\n",
    "                 message_col: str = 'message',\n",
    "                 role_col: str = None,\n",
    "                 delay: float = 3,\n",
    "                 read_kwargs: dict = {},\n",
    "                 gpt_kwargs: dict = {}) -> pd.core.frame.DataFrame:\n",
    "\n",
    "    df = pd.read_csv(path, **read_kwargs)\n",
    "    message_list = df.loc[:, message_col].values\n",
    "    if role_col:\n",
    "        role_list = df.loc[:, role_col].values\n",
    "    else:\n",
    "        role_list = [None] * len(message_list)\n",
    "    assert len(message_list) == len(role_list), 'role列とmessage列の長さが異なります。揃えて再実行して下さい。'\n",
    "    reply_list = []\n",
    "    for role, message in zip(tqdm(role_list), message_list):\n",
    "        reply = send_request(message=message, role=role, delay=delay, **gpt_kwargs)\n",
    "        reply_list.append(reply)\n",
    "    df['reply'] = reply_list\n",
    "    df.to_csv(f'./data/{path[:-4]}_reply.csv', encoding='utf-8-sig', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1bcd6bf-041c-408e-b78a-35bae6fc2aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:26<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "df = reply_to_csv(path='./data/questions.csv',\n",
    "                  message_col='message',\n",
    "                  role_col='role',\n",
    "                  delay=None,\n",
    "                  read_kwargs=dict(encoding='utf-8-sig'),\n",
    "                  gpt_kwargs=dict(temperature=0.7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
