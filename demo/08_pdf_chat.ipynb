{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6700ba3d-4b54-4d69-84be-246e56f6e79e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# LangChainでラクラク！「PDF Chat」\n",
    "[公式ドキュメント](https://python.langchain.com/en/latest/modules/chains/index_examples/chat_vector_db.html)  \n",
    "[参考サイト](https://qiita.com/hiroki_okuhata_int/items/7102bab7d96eb2574e7d)  \n",
    "[参考動画](https://www.youtube.com/watch?v=eCtHVmXcXMs)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdae874-fbcf-4ff6-a72f-63060da81468",
   "metadata": {},
   "source": [
    "# LangChainとは\n",
    "\n",
    "言語モデルを利用してアプリケーションを開発するためのフレームワークです。  \n",
    "[公式サイト](https://python.langchain.com/en/latest/index.html)  \n",
    "[日本語参考サイト](https://zenn.dev/umi_mori/books/prompt-engineer/viewer/langchain_overview)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96cbcafa-556a-4f5b-b567-b14137bdb7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain chromadb pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1e282e-8bce-4343-8832-f5cd0988d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be93e821-989d-46aa-83fe-c295a5652842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY読み込み\n",
    "with open(f'{Path.home()}/.private_info/api_key.txt') as f:\n",
    "    api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f14610f0-6149-4123-a2e3-3e9da133fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# チャット設定\n",
    "class PDFChatAI:\n",
    "\n",
    "    def __init__(self, api_key: str, pdf_path: str, **model_kwargs):\n",
    "        print('Embedding PDF...')\n",
    "        # Embeddingモデルの設定\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "        # PDFをページごとにテキストとして読み込み\n",
    "        pages = PyPDFLoader(pdf_path).load_and_split()\n",
    "        # テキストをベクトル化しデータベースに格納\n",
    "        self.database = Chroma.from_documents(pages, embeddings=embeddings)\n",
    "        print('Embedding complete!')\n",
    "        # ChatGPTモデルの設定\n",
    "        self.llm = ChatOpenAI(model_name='gpt-3.5-turbo', openai_api_key=api_key, **model_kwargs)\n",
    "        # データベースに対してチャットする設定\n",
    "        self.chat = ConversationalRetrievalChain.from_llm(llm=self.llm,\n",
    "                                                          retriever=self.database.as_retriever(),\n",
    "                                                          chain_type='stuff')\n",
    "        self.chat_history = []\n",
    "\n",
    "    def generate(self, question: str):\n",
    "        # Q&A\n",
    "        result = self.chat({'question': question, 'chat_history': self.chat_history})\n",
    "        # チャット履歴を格納\n",
    "        self.chat_history.append((question, result['answer']))\n",
    "        return result['answer']\n",
    "\n",
    "    def clear(self):\n",
    "        # チャット履歴をクリア\n",
    "        self.chat_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830ad2b5-6f5e-42cd-9ec2-88e7c2f0e3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding PDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n",
      "No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding complete!\n"
     ]
    }
   ],
   "source": [
    "qa = PDFChatAI(api_key=api_key, pdf_path='./data/transformer.pdf', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9366196-74e8-41ce-9480-358afebf3dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformerモデルは、エンコーダとデコーダの2つの部分から構成されます。エンコーダは、入力シーケンスを受け取り、それを連続的な表現に変換します。デコーダは、エンコーダが生成した表現を受け取り、出力シーケンスを生成します。両方の部分には、スタックされたセルフアテンションとポイントワイズ、完全に接続されたレイヤーがあります。エンコーダとデコーダの両方に、位置エンコーディングが追加されます。位置エンコーディングは、入力埋め込みに加えられ、シーケンス内のトークンの位置を示します。位置エンコーディングには、サインとコサイン関数を使用することができます。また、マルチヘッドアテンションと呼ばれる機能を使用して、複数のアテンションレイヤーを並列に実行することができます。'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.generate('モデルのアーキテクチャについて要点をまとめてください')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cd88f72-1d58-4d94-88c8-5ee1aac9bf95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but there is no information provided about the pattern of cats in the given context.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.generate('猫の柄についてまとめてください')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c993fa09-f356-49b0-9a83-d98562e774e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('モデルのアーキテクチャについて要点をまとめてください',\n",
       "  'Transformerモデルは、エンコーダとデコーダの2つの部分から構成されます。エンコーダは、入力シーケンスを受け取り、それを連続的な表現に変換します。デコーダは、エンコーダが生成した表現を受け取り、出力シーケンスを生成します。両方の部分には、スタックされたセルフアテンションとポイントワイズ、完全に接続されたレイヤーがあります。エンコーダとデコーダの両方に、位置エンコーディングが追加されます。位置エンコーディングは、入力埋め込みに加えられ、シーケンス内のトークンの位置を示します。位置エンコーディングには、サインとコサイン関数を使用することができます。また、マルチヘッドアテンションと呼ばれる機能を使用して、複数のアテンションレイヤーを並列に実行することができます。'),\n",
       " ('猫の柄についてまとめてください',\n",
       "  \"I'm sorry, but there is no information provided about the pattern of cats in the given context.\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce258661-a8f8-4a35-a309-bf8e71dae1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.clear()\n",
    "qa.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb532cc-3afd-4e42-96fc-ab9933cc5d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'この論文では、Transformerという新しいシーケンス変換モデルが提案されている。このモデルは、エンコーダ・デコーダアーキテクチャで最も一般的に使用される再帰層をマルチヘッドのセルフアテンションに置き換えることで、完全にアテンションに基づくモデルとなっている。このモデルは、従来の再帰層や畳み込み層に基づくアーキテクチャよりも高速に学習できるため、翻訳タスクにおいて従来のモデルよりも高い性能を発揮することができる。また、このモデルは、英語からドイツ語、英語からフランス語の翻訳タスクにおいて、従来のモデルよりも高い性能を発揮することができることが示されている。さらに、このモデルは、英語の構文解析タスクにおいても高い性能を発揮することが示されている。今後は、このモデルを他のタスクにも適用し、入力や出力のモダリティがテキスト以外の場合にも対応できるようにすることが目標とされている。\\n\\nこの論文では、新しいシーケンス変換モデルであるTransformerが提案されています。このモデルは、再帰層をマルチヘッドのセルフアテンションに置き換えることで、完全にアテンションに基づくモデルとなっています。このモデルは、従来のモデルよりも高速に学習できるため、翻訳タスクにおいて従来のモデルよりも高い性能を発揮することができます。また、このモデルは、英語からドイツ語、英語からフランス語の翻訳タスクにおいて、従来のモデルよりも高い性能を発揮することができることが示されています。さらに、このモデルは、英語の構文解析タスクにおいても高い性能を発揮することが示されています。今後は、このモデルを他のタスクにも適用し、入力や出力のモダリティがテキスト以外の場合にも対応できるようにすることが目標とされています。'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.generate('文書全体を要約し、日本語に翻訳して出力してください')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
